{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import (\n",
    "    LlamaForSequenceClassification,\n",
    "    PreTrainedTokenizerFast,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "from peft import PeftModelForSequenceClassification\n",
    "\n",
    "from trl import ModelConfig, get_quantization_config\n",
    "\n",
    "from fed_ppo.utils import (\n",
    "    apply_chat_template,\n",
    "    tokenize,\n",
    "    DatasetFormat,\n",
    "    set_bias,\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# NAMES & PATHS\n",
    "###################################################################################################\n",
    "\n",
    "# Base model path\n",
    "# =================================================================================================\n",
    "BASE_MODEL_PATH = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Reward adapter path\n",
    "# ================================================================================================\n",
    "REWARD_ADAPTER_PATH = \"RLHF-And-Friends/RM-UltrafeedbackBinarized-Llama-3.2-1B-Instruct-Q4-LoRA8-Batch-16-Tok-1024\"\n",
    "\n",
    "# Normalization dataset\n",
    "# =================================================================================================\n",
    "NORM_DATASET_PATH  = \"HuggingFaceH4/ultrachat_200k\"\n",
    "NORM_DATASET_SPLIT = \"train_sft\"\n",
    "\n",
    "# Normalized adapter path to save\n",
    "# =================================================================================================\n",
    "NORM_ADAPTER_PATH = \"RLHF-And-Friends/RM-UltrafeedbackBinarized-Llama-3.2-1B-Instruct-Q4-LoRA8-Batch-16-Tok-1024-Normalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# CONFIGS\n",
    "###################################################################################################\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    torch_dtype               = \"bfloat16\",\n",
    "    load_in_8bit              = False,\n",
    "    load_in_4bit              = True,\n",
    "    bnb_4bit_quant_type       = \"nf4\",\n",
    "    use_bnb_nested_quant      = True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# TOKENIZER & MODELS\n",
    "###################################################################################################\n",
    "\n",
    "# Tokenizer\n",
    "# =================================================================================================\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    REWARD_ADAPTER_PATH, \n",
    "    use_fast=True,\n",
    "    pad_token = \"<|pad|>\"\n",
    ")\n",
    "\n",
    "# Model\n",
    "# =================================================================================================\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "quantization_config = get_quantization_config(model_config)\n",
    "\n",
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    num_labels = 1,\n",
    "    quantization_config = quantization_config,\n",
    "    torch_dtype = getattr(torch, model_config.torch_dtype),\n",
    ")\n",
    "# Enable bias in the head\n",
    "set_bias(\n",
    "    base_model, \n",
    "    layer_path=\"score\", \n",
    "    bias=0.0, \n",
    "    dtype=getattr(torch, model_config.torch_dtype)\n",
    ")\n",
    "\n",
    "model = PeftModelForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    REWARD_ADAPTER_PATH\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Sync padding tokens\n",
    "# =================================================================================================\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# DATASET\n",
    "###################################################################################################\n",
    "\n",
    "# Load dataset\n",
    "# =================================================================================================\n",
    "\n",
    "dataset = load_dataset(\n",
    "    NORM_DATASET_PATH\n",
    ")[NORM_DATASET_SPLIT]\n",
    "\n",
    "dataset = dataset.select(range(1000))\n",
    "\n",
    "# Apply chat template\n",
    "# =================================================================================================\n",
    "\n",
    "dataset = dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs = {\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"columns_to_apply_to\": [\"messages\"],\n",
    "        \"dataset_format\": DatasetFormat.CONVERSATIONAL,\n",
    "        \"add_generation_prompt\": False,\n",
    "        \"new_columns\": [\"chat\"],\n",
    "    },\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "# Tokenize\n",
    "# =================================================================================================\n",
    "\n",
    "dataset = dataset.map(\n",
    "    tokenize,\n",
    "    fn_kwargs = {\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"columns_to_apply_to\": [\"chat\"],\n",
    "        \"columns_for_ids\": [\"input_ids\"],\n",
    "        \"columns_for_attn\": [\"attention_mask\"]\n",
    "    },\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# Create dataloader\n",
    "# =================================================================================================\n",
    "\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    collate_fn=DataCollatorWithPadding(tokenizer),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:04<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 0.5853118896484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# Normalization\n",
    "###################################################################################################\n",
    "\n",
    "reward_sum = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        logits = model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).logits\n",
    "        reward_sum += torch.mean(logits).item()\n",
    "\n",
    "mean_reward = reward_sum / len(dataloader)\n",
    "\n",
    "print(f\"Mean reward: {mean_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New bias: tensor([-0.5859], device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/RLHF-And-Friends/RM-UltrafeedbackBinarized-Llama-3.2-1B-Instruct-Q4-LoRA8-Batch-16-Tok-1024-Normalized/commit/708343673ea1773f1f7ddd371ee3db1186d318ac', commit_message='Upload tokenizer', commit_description='', oid='708343673ea1773f1f7ddd371ee3db1186d318ac', pr_url=None, repo_url=RepoUrl('https://huggingface.co/RLHF-And-Friends/RM-UltrafeedbackBinarized-Llama-3.2-1B-Instruct-Q4-LoRA8-Batch-16-Tok-1024-Normalized', endpoint='https://huggingface.co', repo_type='model', repo_id='RLHF-And-Friends/RM-UltrafeedbackBinarized-Llama-3.2-1B-Instruct-Q4-LoRA8-Batch-16-Tok-1024-Normalized'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# Add bias to the head and save\n",
    "###################################################################################################\n",
    "\n",
    "# Set bias\n",
    "# =================================================================================================\n",
    "\n",
    "set_bias(\n",
    "    model, \n",
    "    layer_path=\"score.modules_to_save.default\",\n",
    "    bias = -mean_reward\n",
    ")\n",
    "\n",
    "# Remove pad token and save\n",
    "# =================================================================================================\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer) - 1)\n",
    "\n",
    "print(f\"New bias: {model.score.modules_to_save.default.bias.data}\")\n",
    "\n",
    "model.push_to_hub(NORM_ADAPTER_PATH)\n",
    "tokenizer.push_to_hub(NORM_ADAPTER_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".fed-ppo-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
